# ğŸº Lubbock Bar Hopping Route Optimizer

An AI-powered bar hopping assistant that optimizes your night out in Lubbock, Texas. Uses a fine-tuned Microsoft Phi-3.5 language model to understand natural language requests and generate conversational responses.

## What This Project Does

You tell it something like *"yo let's hit Chimy's and Cricket's at 9pm"* and it:
1. **Understands** your casual language (handles typos, nicknames, etc.)
2. **Optimizes** the order of bars to minimize your total wait time
3. **Responds** with a friendly, AI-generated itinerary

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend    â”‚  HTTP   â”‚       FastAPI Backend           â”‚
â”‚   (Vercel - free)   â”‚ â—„â”€â”€â”€â”€â”€â–º â”‚     (Railway Pro - $5/mo)       â”‚
â”‚                     â”‚         â”‚                                 â”‚
â”‚  - Chat Interface   â”‚         â”‚  - NLU Service (parsing)        â”‚
â”‚  - Route Display    â”‚         â”‚  - Simulation (optimization)    â”‚
â”‚  - Model Status     â”‚         â”‚  - LLM Service (Phi-3.5)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
bar-hopping-app/
â”œâ”€â”€ backend/                    # FastAPI Python server
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py            # Entry point, CORS config
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ optimizer.py   # API endpoints
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ nlu.py         # Natural language understanding
â”‚   â”‚       â”œâ”€â”€ simulation.py  # Route optimization
â”‚   â”‚       â””â”€â”€ model.py       # LLM integration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ railway.toml
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/                   # React web application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx/.css
â”‚   â”‚   â”‚   â”œâ”€â”€ RouteDisplay.jsx/.css
â”‚   â”‚   â”‚   â””â”€â”€ BarList.jsx/.css
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Quick Start (Local Development)

### Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env: set MODEL_BACKEND=disabled for testing without GPU
uvicorn app.main:app --reload --port 8000
```

### Frontend
```bash
cd frontend
npm install
cp .env.example .env.local
npm run dev
```

Visit http://localhost:5173

## Deployment

See the **Complete_Deployment_Guide.pdf** for step-by-step instructions.

**Quick summary:**
1. Push code to GitHub
2. Deploy backend to Railway Pro (has GPU support)
3. Deploy frontend to Vercel (free)
4. Configure environment variables

## Environment Variables

### Backend (Railway)
| Variable | Description |
|----------|-------------|
| MODEL_BACKEND | `local` (GPU), `huggingface`, or `disabled` |
| HF_MODEL_ID | `microsoft/Phi-3.5-mini-instruct` |
| HF_LORA_ID | Your fine-tuned adapter from HuggingFace Hub |
| ALLOWED_ORIGINS | Your Vercel frontend URL |

### Frontend (Vercel)
| Variable | Description |
|----------|-------------|
| VITE_API_URL | Your Railway backend URL + `/api` |

## Tech Stack

- **Frontend:** React 18, Vite, Axios, Lucide React
- **Backend:** FastAPI, Pydantic, uvicorn
- **ML:** PyTorch, Transformers, PEFT, bitsandbytes
- **Model:** Microsoft Phi-3.5-mini-instruct with LoRA fine-tuning

## Authors

Hannah Juscelino-Diogo & Jovi Ukwade
