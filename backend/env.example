# =============================================================================
# Backend Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# In Railway, set these as environment variables in the dashboard
# =============================================================================

# Model Backend: "local" (GPU), "huggingface" (API), or "disabled" (no LLM)
MODEL_BACKEND=local

# Base model from HuggingFace Hub
HF_MODEL_ID=microsoft/Phi-3.5-mini-instruct

# Your fine-tuned LoRA adapter (upload to HuggingFace Hub from Kaggle)
# Example: yourusername/bar-hopping-phi35-lora
HF_LORA_ID=

# HuggingFace API token (optional, for private models or HF Inference)
HF_API_TOKEN=

# HuggingFace Inference Endpoint URL (if using huggingface backend)
HF_INFERENCE_URL=

# CORS: Comma-separated list of frontend URLs allowed to access this API
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000
